# Goコードの記述と最適化

このドキュメントでは、高性能なGoコードを記述するためのベストプラクティスについて説明します。

現時点では、ビデオ、スライド、ブログ記事（「awesome-golang-performance」など）へのリンク集ですが、コンテンツが外部でなくここにある、より長い本形式に進化させるつもりです。リンクはカテゴリ別にソートする必要があります。

個々のサービスの高速化（キャッシングなど）についていくつか議論を行いますが、高パフォーマンスな分散システムの設計は範囲外です。まったく異なる一連の研究と設計のトレードオフを網羅しています。

すべてのコンテンツはCC-BY-SAの下でライセンスされます。

この本はつぎのセクションに分かれています。
   1) 遅くないソフトウェアを書くための基本的なヒント
     * CS 101-level のコンテンツ
   2) 高速なソフトウェアを書くためのヒント
     * Goの性能の引き出し方に関するGo固有のセクション
   3) *本当*に高速なソフトウェアを書くための高度なヒント
     * 最適化されたコードに高速化の余地がある場合

これらの3つのセクションを以下のように要約できます。
- 愚かになるな
- 賢くなれ
- 危険をおかせ

### いつ、どこを最適化するか

本当に最も重要なステップなので最初に書きます。あなたは最適化を行うべきなのでしょうか？

すべての最適化にはコストがかかります。一般的に、このコストはコードの複雑さか認知負荷の観点で表現されます。つまり、最適化されたコードは最適化されていないバージョンよりもシンプルであることは滅多にありません。

しかし、最適化の経済という別の側面があります。プログラマーとして、あなたの時間は貴重です。バグ修正や機能追加など、プロジェクトにおいて取り組む機会機会費用があります。最適化するのは楽しいですが、選択するのがしつも適切な仕事ではありません。パフォーマンスは機能ですが、リリースや品質もしかりです。

作業する最重要なものを選択するのです。それは時にはCPU最適化ではなく、ユーザーエクスペリエンスです。プログレスバーを追加するシンプルなものだったり、ページのレンダリング後にバックグラウンドで処理してページのレスポンスを改善することだったりします。

3時間後の毎時レポートが1時間もかからないレポートより役に立たないこともあるのです。

簡単に最適化できるからといっても最適化する価値があるわけではありません。容易に解決できる問題を無視することは有効な開発戦略です。

これを*あなたの*時間最適化だと考えてください。

何を最適化すべきかを選択し、いつ最適化すべきかを選択するのです。

「時期尚早な最適化」を定義してください。97%がそうですが、重要な3%に取り組んでください。

TPOP: 最適化すべきだろうか？「すべきだ。しかし、プログラムが本当に遅すぎ、問題が重要であるときに限る上に、正確さ、堅牢性、明快さを維持しつつ高速化されるという期待がある」

高速なソフトウェアか高速な開発です。

http://bitfunnel.org/strangeloop に数値があります。1台につき年1000USドルする機器が3万台必要な架空の検索エンジンを想像してください。ソフトウェアのスピードを倍増させることで年間1500万ドルを節約できます。1%削減するために開発者が1年取り組んでも割りに合うでしょう。

たいていの場合、プログラムのサイズとスピードは重要ではありません。至極単純な最適化は行う必要がありません。2番目に簡単な最適化は、より速いハードウェアを購入することです。

プログラムを変更しようと決めたら、続きを読んでください。

### 最適化方法

## 最適化の手順

詳細の前に、最適化の一般的なプロセスについて説明します。

最適化はリファクタリングの一種です。しかし、各ステップではソースコードのいくつかの側面（コードの重複、明快さなど）を改善するのではなく、パフォーマンスのいくつかの側面を改善します。たとえば、CPUやメモリ使用低減、レイテンシの低減などです。この改善は、一般的に可読性を犠牲にします。つまり、ユニットテストの包括的なセットに加え（変更が何かを壊していないことを保証するため）、変更がパフォーマンスに望ましい影響を与えているのを確認するために良いベンチマークセットが必要ということです。変更が実際にCPU使用を減少させていることを確認できる必要があります。改善すると思った変更は、実際にはゼロか負の影響を及ぼすこともあります。このような場合には必ず修正を元に戻してください。

https://stackoverflow.com/questions/184618/what-is-the-best-comment-in-source-code-you-have-ever-encountered

```go
//
// 親愛なる保守者様
//
// このルーチンを最適化しようとして
// それがひどい間違いだったと気づいたら
// 次の保守者への警告として下記のカウンターを
// インクリメントしてください
//
// total_hours_wasted_here = 42
//
```

使用しているベンチマークは正確で、代表的なワークロードで再現可能な数値を提供する必要があります。個別実行の分散が大きすぎると、小さな改善を見つけるのが難しくなります。あなたはベンチスタットかそれに相当する統計テストを使用する必要があり、そこから目を背けることはできません。（いずれにしても統計的なテストを使うのは良い考えです。）ベンチマークを実行する手順は文書化され、カスタムスクリプトとツールは実行方法の説明と一緒にリポジトリにコミットされているべきです。実行に時間がかかる大きなベンチマークスイートに注意してください。開発のイテレーションが遅くなります。

測定できるものはすべて最適化できることにも注意してください。正しいものを測定していることを確認してください。

次のステップは、最適化するものの決定です。目標がCPUを改善することであれば、許容できるスピードはどれくらいでしょうか。現在のパフォーマンスを2倍にしたいですか？10倍にしたいですか？「時間T未満のサイズNの問題」と捉えられますか？メモリ使用量を減らそうとしていますか？どれくらいですか？メモリ使用のなんの変化に対してどれだけ遅くなってもかまいませんか？小スペース化と引き換えに、なにを諦めますか？

サービスのレイテンシーのための最適化はより難しい提案です。Webサーバーのパフォーマンスをテストする方法については、書籍全体を通して書かれています。主な問題は、シングルスレッドコードの場合特定の問題サイズでパフォーマンスがかなり一定であることです。Webサービスの場合は単一値ではありません。適切なWebサービスベンチマークスイートは、特定のリクエスト/秒レベルのレイテンシ分布を提供します。（Gil Teneさんのお話へのリンクを貼る予定）

パフォーマンス目標は具体的でなければなりません。あなたは（ほとんど）より速いものを作ることができるでしょう。最適化はしばしば収穫逓減のゲームです。いつ止めるべきかを知る必要があります。仕事の最後のほんの少しを得るためにどれほどの努力を払うのでしょうか？どれほど醜くメンテナンスしにくいコードが書きたいのでしょうか？

ダン・ルーもまた目標パフォーマンス数値が妥当かどうかを判断するための大まかな計算の利点も指摘しています。

グリーンフィールド開発では、最後までベンチマーキングとパフォーマンスの数値を置き去りにすべきではありません。「後で修正する」と言うのは簡単ですが、パフォーマンスが本当に重要な場合は、最初から設計上の検討事項です。パフォーマンスの問題を修正するために必要なアーキテクチャ上の大幅な変更は、締め切り近くでは危険です。開発*期間中*は、合理的なプログラム設計、アルゴリズム、データ構造に焦点を当てるべきであることに注意してください。スタックの下位レベルでの最適化は、システムパフォーマンスのより完全な見通しがつく開発サイクルの後半まで待つべきです。システムが不完全な間にフルシステムプロファイルを取得しても、完成したシステムのどこにボトルネックの所在を見誤ります。

[幾千の傷による死](https://en.wikipedia.org/wiki/Death_by_a_Thousand_Cuts_(book))です。

ベンチマークできるコードを書いてください。大きなシステムではできる限りプロファイルしてください。テストしたい孤立した部分をベンチマークしてください。ベンチマークで十分にテストされ、代表的なものである十分なコンテキストを抽出して設定できる必要があります。

ターゲットと現在のパフォーマンスとの差異から、どこから始めるべきかを知ることができます。10％〜20％のパフォーマンス上が必要なだけの場合は、おそらくいくらかの実装の調整や軽微な修正で間に合うでしょう。10倍以上の最適化が必要な場合は、乗算を左シフトで置き換えるだけでは達成できません。おそらくあなたのスタックの変化が必要でしょう。

優れたパフォーマンスの作業には、システム設計、ネットワーキング、ハードウェア（CPU、キャッシュ、ストレージ）、アルゴリズム、チューニング、デバッグなど、さまざまなレベルの知識が必要です。限られた時間とリソースで、どのレベルが最も改善をもたらすかを検討してください。いつもアルゴリズムやプログラムのチューニングとは限りません。

この本では主にCPU使用、メモリ使用、レイテンシの低減を扱います。3つすべてを行うことは滅多にできないことを指摘しておきます。おそらく、CPU時間を高速化すると、プログラムはより多くのメモリを使用するでしょう。おそらく、メモリ空間を減らす必要があるとき、プログラムはより長い時間を要するでしょう。

アムダールの法則ではボトルネックに焦点を当てるべきとされています。ランタイムの5％しか必要としないルーチンの速度を2倍にしても、正味2.5%のスピードアップにしかなりません。一方、80%の時間を占めるルーチンを10%スピードアップさせるだけでも8%近く実行時間を改善できます。プロファイルは時間が実際に費やされた場所を特定するのに役立ちます。

最適化の際、CPUの仕事量を減らしたいとしましょう。同じ問題（ソート）をより少ないステップで解決するため、クイックソートはバブルソートよりも高速です。より効率的なアルゴリズムです。同じタスクを達成するためにCPUが行う必要がある作業を減らしました。

コンパイラの最適化と同様、プログラムのチューニングは通常、ランタイム全体でわずかな減少しかもたらしません。ほとんどの場合、アルゴリズムの変更やデータ構造の変更等、プログラムの構成方法の根本的な変更により効果の大きい最適化を実現できます。コンパイラ技術は向上していますが、スピードはゆっくりです。[Proebstingの法則](http://proebsting.cs.arizona.edu/law.html)ではコンパイラの性能は18年毎に倍になるとされており、これはプロセッサの性能は18カ月ごとに倍になるという（少し解釈が誤解されている）ムーアの法則と対照的です。アルゴリズムの改善は、より大きい規模で機能します。[混合整数プログラミングのアルゴリズムは、1991年から2008年の間に3万倍向上しました。](https://agtb.wordpress.com/2010/12/23/progress-in-algorithms-beats-moore%E2%80%99s-law/)より具体的な例として、Uberのブログ記事で説明されているブルートフォース地理空間アルゴリズムをより専門的なもの、よりタスクに適したものに置き換える詳細について考えてみましょう。 https://medium.com/@buckhx/unwinding-uber-s-most-efficient-service-406413c5871d

プロファイラは、特定のルーチンで多くの時間が費やされていることを示すことがあります。これは高コストのルーチンなのかもしれませんし、単に何度も呼ばれている低コストのルーチンかもしれません。すぐにその1つのルーチンをスピードアップしようとするのではなく、呼び出された回数を減らしたり、完全に無くしたりできるかどうかを確認してください。より具体的な最適化戦略については次のセクションで説明します。

最適化に関するクイズが3つあります。

- 最適化する必要がありますか？最速のコードは決して実行されないコードです。
- もし必要があるなら、これは最良のアルゴリズムでしょうか？
- もし必要があるなら、これはそのアルゴリズムの最良の*実装*でしょうか？



