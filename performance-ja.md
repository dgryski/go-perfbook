# Goコードの記述と最適化

このドキュメントでは、高性能なGoコードを記述するためのベストプラクティスについて説明します。

現時点では、ビデオ、スライド、ブログ記事（「awesome-golang-performance」など）へのリンク集ですが、コンテンツが外部でなくここにある、より長い本形式に進化させるつもりです。リンクはカテゴリ別にソートする必要があります。

個々のサービスの高速化（キャッシングなど）についていくつか議論を行いますが、高パフォーマンスな分散システムの設計は範囲外です。まったく異なる一連の研究と設計のトレードオフを網羅しています。

すべてのコンテンツはCC-BY-SAの下でライセンスされます。

この本はつぎのセクションに分かれています。
   1) 遅くないソフトウェアを書くための基本的なヒント
     * CS 101-level のコンテンツ
   2) 高速なソフトウェアを書くためのヒント
     * Goの性能の引き出し方に関するGo固有のセクション
   3) *本当*に高速なソフトウェアを書くための高度なヒント
     * 最適化されたコードに高速化の余地がある場合

これらの3つのセクションを以下のように要約できます。
- 愚かになるな
- 賢くなれ
- 危険をおかせ

### いつ、どこを最適化するか

本当に最も重要なステップなので最初に書きます。あなたは最適化を行うべきなのでしょうか？

すべての最適化にはコストがかかります。一般的に、このコストはコードの複雑さか認知負荷の観点で表現されます。つまり、最適化されたコードは最適化されていないバージョンよりもシンプルであることは滅多にありません。

しかし、最適化の経済という別の側面があります。プログラマーとして、あなたの時間は貴重です。バグ修正や機能追加など、プロジェクトにおいて取り組む機会機会費用があります。最適化するのは楽しいですが、選択するのがしつも適切な仕事ではありません。パフォーマンスは機能ですが、リリースや品質もしかりです。

作業する最重要なものを選択するのです。それは時にはCPU最適化ではなく、ユーザーエクスペリエンスです。プログレスバーを追加するシンプルなものだったり、ページのレンダリング後にバックグラウンドで処理してページのレスポンスを改善することだったりします。

3時間後の毎時レポートが1時間もかからないレポートより役に立たないこともあるのです。

簡単に最適化できるからといっても最適化する価値があるわけではありません。容易に解決できる問題を無視することは有効な開発戦略です。

これを*あなたの*時間最適化だと考えてください。

何を最適化すべきかを選択し、いつ最適化すべきかを選択するのです。

「時期尚早な最適化」を定義してください。97%がそうですが、重要な3%に取り組んでください。

TPOP: 最適化すべきだろうか？「すべきだ。しかし、プログラムが本当に遅すぎ、問題が重要であるときに限る上に、正確さ、堅牢性、明快さを維持しつつ高速化されるという期待がある」

高速なソフトウェアか高速な開発です。

http://bitfunnel.org/strangeloop に数値があります。1台につき年1000USドルする機器が3万台必要な架空の検索エンジンを想像してください。ソフトウェアのスピードを倍増させることで年間1500万ドルを節約できます。1%削減するために開発者が1年取り組んでも割りに合うでしょう。

たいていの場合、プログラムのサイズとスピードは重要ではありません。至極単純な最適化は行う必要がありません。2番目に簡単な最適化は、より速いハードウェアを購入することです。

プログラムを変更しようと決めたら、続きを読んでください。

### 最適化方法

## 最適化の手順

詳細の前に、最適化の一般的なプロセスについて説明します。

最適化はリファクタリングの一種です。しかし、各ステップではソースコードのいくつかの側面（コードの重複、明快さなど）を改善するのではなく、パフォーマンスのいくつかの側面を改善します。たとえば、CPUやメモリ使用低減、レイテンシの低減などです。この改善は、一般的に可読性を犠牲にします。つまり、ユニットテストの包括的なセットに加え（変更が何かを壊していないことを保証するため）、変更がパフォーマンスに望ましい影響を与えているのを確認するために良いベンチマークセットが必要ということです。変更が実際にCPU使用を減少させていることを確認できる必要があります。改善すると思った変更は、実際にはゼロか負の影響を及ぼすこともあります。このような場合には必ず修正を元に戻してください。

https://stackoverflow.com/questions/184618/what-is-the-best-comment-in-source-code-you-have-ever-encountered

```go
//
// 親愛なる保守者様
//
// このルーチンを最適化しようとして
// それがひどい間違いだったと気づいたら
// 次の保守者への警告として下記のカウンターを
// インクリメントしてください
//
// total_hours_wasted_here = 42
//
```

使用しているベンチマークは正確で、代表的なワークロードで再現可能な数値を提供する必要があります。個別実行の分散が大きすぎると、小さな改善を見つけるのが難しくなります。あなたはベンチスタットかそれに相当する統計テストを使用する必要があり、そこから目を背けることはできません。（いずれにしても統計的なテストを使うのは良い考えです。）ベンチマークを実行する手順は文書化され、カスタムスクリプトとツールは実行方法の説明と一緒にリポジトリにコミットされているべきです。実行に時間がかかる大きなベンチマークスイートに注意してください。開発のイテレーションが遅くなります。

測定できるものはすべて最適化できることにも注意してください。正しいものを測定していることを確認してください。

次のステップは、最適化するものの決定です。目標がCPUを改善することであれば、許容できるスピードはどれくらいでしょうか。現在のパフォーマンスを2倍にしたいですか？10倍にしたいですか？「時間T未満のサイズNの問題」と捉えられますか？メモリ使用量を減らそうとしていますか？どれくらいですか？メモリ使用のなんの変化に対してどれだけ遅くなってもかまいませんか？小スペース化と引き換えに、なにを諦めますか？

サービスのレイテンシーのための最適化はより難しい提案です。Webサーバーのパフォーマンスをテストする方法については、書籍全体を通して書かれています。主な問題は、シングルスレッドコードの場合特定の問題サイズでパフォーマンスがかなり一定であることです。Webサービスの場合は単一値ではありません。適切なWebサービスベンチマークスイートは、特定のリクエスト/秒レベルのレイテンシ分布を提供します。（Gil Teneさんのお話へのリンクを貼る予定）

パフォーマンス目標は具体的でなければなりません。あなたは（ほとんど）より速いものを作ることができるでしょう。最適化はしばしば収穫逓減のゲームです。いつ止めるべきかを知る必要があります。仕事の最後のほんの少しを得るためにどれほどの努力を払うのでしょうか？どれほど醜くメンテナンスしにくいコードが書きたいのでしょうか？

ダン・ルーもまた目標パフォーマンス数値が妥当かどうかを判断するための大まかな計算の利点も指摘しています。

グリーンフィールド開発では、最後までベンチマーキングとパフォーマンスの数値を置き去りにすべきではありません。「後で修正する」と言うのは簡単ですが、パフォーマンスが本当に重要な場合は、最初から設計上の検討事項です。パフォーマンスの問題を修正するために必要なアーキテクチャ上の大幅な変更は、締め切り近くでは危険です。開発*期間中*は、合理的なプログラム設計、アルゴリズム、データ構造に焦点を当てるべきであることに注意してください。スタックの下位レベルでの最適化は、システムパフォーマンスのより完全な見通しがつく開発サイクルの後半まで待つべきです。システムが不完全な間にフルシステムプロファイルを取得しても、完成したシステムのどこにボトルネックの所在を見誤ります。

[幾千の傷による死](https://en.wikipedia.org/wiki/Death_by_a_Thousand_Cuts_(book))です。

ベンチマークできるコードを書いてください。大きなシステムではできる限りプロファイルしてください。テストしたい孤立した部分をベンチマークしてください。ベンチマークで十分にテストされ、代表的なものである十分なコンテキストを抽出して設定できる必要があります。

ターゲットと現在のパフォーマンスとの差異から、どこから始めるべきかを知ることができます。10％〜20％のパフォーマンス上が必要なだけの場合は、おそらくいくらかの実装の調整や軽微な修正で間に合うでしょう。10倍以上の最適化が必要な場合は、乗算を左シフトで置き換えるだけでは達成できません。おそらくあなたのスタックの変化が必要でしょう。

優れたパフォーマンスの作業には、システム設計、ネットワーキング、ハードウェア（CPU、キャッシュ、ストレージ）、アルゴリズム、チューニング、デバッグなど、さまざまなレベルの知識が必要です。限られた時間とリソースで、どのレベルが最も改善をもたらすかを検討してください。いつもアルゴリズムやプログラムのチューニングとは限りません。

この本では主にCPU使用、メモリ使用、レイテンシの低減を扱います。3つすべてを行うことは滅多にできないことを指摘しておきます。おそらく、CPU時間を高速化すると、プログラムはより多くのメモリを使用するでしょう。おそらく、メモリ空間を減らす必要があるとき、プログラムはより長い時間を要するでしょう。

アムダールの法則ではボトルネックに焦点を当てるべきとされています。ランタイムの5％しか必要としないルーチンの速度を2倍にしても、正味2.5%のスピードアップにしかなりません。一方、80%の時間を占めるルーチンを10%スピードアップさせるだけでも8%近く実行時間を改善できます。プロファイルは時間が実際に費やされた場所を特定するのに役立ちます。

最適化の際、CPUの仕事量を減らしたいとしましょう。同じ問題（ソート）をより少ないステップで解決するため、クイックソートはバブルソートよりも高速です。より効率的なアルゴリズムです。同じタスクを達成するためにCPUが行う必要がある作業を減らしました。

コンパイラの最適化と同様、プログラムのチューニングは通常、ランタイム全体でわずかな減少しかもたらしません。ほとんどの場合、アルゴリズムの変更やデータ構造の変更等、プログラムの構成方法の根本的な変更により効果の大きい最適化を実現できます。コンパイラ技術は向上していますが、スピードはゆっくりです。[Proebstingの法則](http://proebsting.cs.arizona.edu/law.html)ではコンパイラの性能は18年毎に倍になるとされており、これはプロセッサの性能は18カ月ごとに倍になるという（少し解釈が誤解されている）ムーアの法則と対照的です。アルゴリズムの改善は、より大きい規模で機能します。[混合整数プログラミングのアルゴリズムは、1991年から2008年の間に3万倍向上しました。](https://agtb.wordpress.com/2010/12/23/progress-in-algorithms-beats-moore%E2%80%99s-law/)より具体的な例として、Uberのブログ記事で説明されているブルートフォース地理空間アルゴリズムをより専門的なもの、よりタスクに適したものに置き換える詳細について考えてみましょう。 https://medium.com/@buckhx/unwinding-uber-s-most-efficient-service-406413c5871d

プロファイラは、特定のルーチンで多くの時間が費やされていることを示すことがあります。これは高コストのルーチンなのかもしれませんし、単に何度も呼ばれている低コストのルーチンかもしれません。すぐにその1つのルーチンをスピードアップしようとするのではなく、呼び出された回数を減らしたり、完全に無くしたりできるかどうかを確認してください。より具体的な最適化戦略については次のセクションで説明します。

最適化に関する質問が3つあります。

- 最適化する必要がありますか？最速のコードは決して実行されないコードです。
- もし必要があるなら、これは最良のアルゴリズムでしょうか？
- もし必要があるなら、これはそのアルゴリズムの最良の*実装*でしょうか？

### 具体的な最適化のヒント

Jon Bentleyの「効率的なプログラム記述」（1982年）ではエンジニアリングの問題としてプログラム最適化を取り扱いました。ベンチマーク。分析。改善。検証。反復。彼のヒントの多くは、現在ではコンパイラが自動的に実行します。プログラマーの仕事は、コンパイラーが*できない*変換を使用することです。

この本の要約です。
http://www.crowl.org/lawrence/programming/Bentley82.html
http://www.geoffprewett.com/BookReviews/WritingEfficientPrograms.html

プログラムチューニングのルールです。
https://web.archive.org/web/20080513070949/http://www.cs.bell-labs.com/cm/cs/pearls/apprules.html

プログラムの変更を考える際、2つの基本的な選択肢があります。データを変えるかコードを変えるかです。

## データの変更

データを変更するとは、処理しているデータの表現を追加したり変更したりするということです。

（これらの中には、データ構造のさまざまな側面に関連するO()の変更に依存するものがあります）

データ構造を拡張するためのアイデア:

- 追加のフィールド: たとえば、リンクトリストのサイズは必要なときにイテレーションするのではなく格納してください。もしくは頻繁に必要とされる他のノードへの追加のポインタを複数の検索に格納してください（たとえば二十リンクトリストでO(1)を削除するための「後方」リンク）。このような変更は、必要なデータの保存と最新の状態の維持が低コストな場合に役立ちます。

- 追加の検索インデックス: ほとんどのデータ構造は、単一タイプのクエリ用に設計されています。2つの異なるクエリタイプが必要な場合は、データに「ビュー」を追加することで大幅な改善が可能です。たとえば、IDによって参照される[]structやときにはmap[string]idのstring（もしくは*struct）

- 追加の要素情報: たとえばブルームフィルタです。これらは、データ構造の残りの部分を圧倒しないように、小さくて速い必要があります。

- クエリが高コストな場合は、キャッシュを追加してください。私たちはmemcacheに精通していますが、インプロセスキャッシュが存在します。
  * ワイヤー越しのネットワークとシリアライゼーションのコストは大きいです
  * インプロセスキャッシュでは失効を気にする必要があります。
  * 単一の項目でも役立ちます（たとえばログファイルの時間解析）

TODO: 「キャッシュ」はキーバリューではなく、作業していた場所へのポインタにすぎません。これは「サーチフィンガー」と同じくらいシンプルになり得ます。

これらはすべて、データ構造レベルで「仕事を減らす」という明確な例です。すべて空間コストがかかります。ほとんどの場合、CPUを最適化すると、プログラムはより多くのメモリを使用します。これは古典的な時間と空間のトレードオフです。
https://en.wikipedia.org/wiki/Space%E2%80%93time_tradeoff

プログラムがあまりにも多くのメモリを使用している場合は、逆の方法を取ることもできます。計算量の増加と引き換えに空間の使用量を減らすのです。事柄を保存するのではなく、毎回計算します。メモリ内にデータを圧縮し、必要に応じて即座に圧縮解除することもできます。

プログラムが使用する空間を減少させるテクニックをカバーした本をオンラインで利用できます。もともと組み込み開発者を対象に書かれていましたが、膨大な量のデータを処理する最新のハードウェア上のプログラムにも当てはまります。
http://www.smallmemory.com/

データを並べ替えてください。パディングを削除するのです。追加のフィールドを削除してください。遅いデータ構造に変更してください。ポインタの重いツリー構造をスキップし、代わりにスライスと線形検索を使用してください。データの圧縮方法をカスタマイズしてください。浮動小数点（go-tsz）や整数（deltaやxorとhuffman）などが利用できます。

データレイアウトについては後で詳しく説明します。

現代のコンピュータとメモリ階層は、空間と時間のトレードオフをあまり明確にしません。メモリ上で「遠く離れている」（それゆえアクセスにコストがかかる）テーブルの探索は
必要なときに再計算するだけで速くなります。

これはまた、キャッシュ競合により本番環境では実現されない改善が頻繁に見られることを意味します。（たとえば、テーブル探索はベンチマーク時にプロセッサキャッシュに格納されますが、実際のシステムで使用する場合は常に「実データ」でフラッシュされます。GoogleのJump Hash論文では、プロセッサキャッシュの満たすものと満たさないものの両方を比較しながらこれを直接的に述べています。Jump Hash論文のグラフ4と5を見てください https://arxiv.org/pdf/1406.2294.pdf ）

TODO: コンテンツキャッシュをシミュレートする方法、増分コストを表示する方法

考慮すべき別の側面は、データ転送時間です。一般的に、ネットワークとディスクへのアクセスは非常に遅いため、圧縮されたチャンクを読み込めるようになると、取得されたデータを解凍するのに必要なCPU時間よりもずっと高速になります。ここで、いつものようにベンチバークが重要です。バイナリ形式は一般的にテキスト形式よりも小さく、高速に解析することができますが、人間は読めなくなってしまいます。


